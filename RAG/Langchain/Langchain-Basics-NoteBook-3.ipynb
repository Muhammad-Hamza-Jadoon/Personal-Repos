{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13bab812-9a26-48f8-9d03-27e32d02d117",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/custom-json-schema",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import langchain\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from langchain_together import Together\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticOutputParser\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_together\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Together\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_together\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This package provides the Together integration for LangChain.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_together\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatTogether\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_together\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TogetherEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_together\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Together\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_together\\chat_models.py:18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, SecretStr, root_validator\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     convert_to_secret_str,\n\u001b[0;32m     16\u001b[0m     get_from_dict_or_env,\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChatTogether\u001b[39;00m(BaseChatOpenAI):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"ChatTogether chat model.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    Setup:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_openai\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_openai\\chat_models\\azure.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_calling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_openai_tool\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_basemodel_subclass\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[0;32m     43\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     46\u001b[0m _BM \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_BM\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mBaseModel)\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:298\u001b[0m\n\u001b[0;32m    294\u001b[0m     parsed: Optional[_DictOrPydantic]\n\u001b[0;32m    295\u001b[0m     parsing_error: Optional[\u001b[38;5;167;01mBaseException\u001b[39;00m]\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mBaseChatOpenAI\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_client\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:224\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_wrapper\u001b[38;5;241m.\u001b[39mfrozen \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__hash__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace:\n\u001b[0;32m    222\u001b[0m     set_default_hash_func(\u001b[38;5;28mcls\u001b[39m, bases)\n\u001b[1;32m--> 224\u001b[0m \u001b[43mcomplete_model_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypes_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes_namespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_model_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_create_model_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# If this is placed before the complete_model_class call above,\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# the generic computed fields return type is set to PydanticUndefined\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_computed_fields \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_decorators__\u001b[38;5;241m.\u001b[39mcomputed_fields\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:577\u001b[0m, in \u001b[0;36mcomplete_model_class\u001b[1;34m(cls, cls_name, config_wrapper, raise_errors, types_namespace, create_model_module)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_pydantic_core_schema__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\main.py:671\u001b[0m, in \u001b[0;36mBaseModel.__get_pydantic_core_schema__\u001b[1;34m(cls, source, handler)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_generic_metadata__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_core_schema__\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:83\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[1;34m(self, source_type)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[1;32m---> 83\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:655\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[1;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[0;32m    652\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:924\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lenient_issubclass(obj, BaseModel):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type_stack\u001b[38;5;241m.\u001b[39mpush(obj):\n\u001b[1;32m--> 924\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:739\u001b[0m, in \u001b[0;36mGenerateSchema._model_schema\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    727\u001b[0m     model_schema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_schema(\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    729\u001b[0m         inner_schema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    735\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    736\u001b[0m     )\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    738\u001b[0m     fields_schema: core_schema\u001b[38;5;241m.\u001b[39mCoreSchema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mmodel_fields_schema(\n\u001b[1;32m--> 739\u001b[0m         {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_md_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    740\u001b[0m         computed_fields\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    741\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed_field_schema(d, decorators\u001b[38;5;241m.\u001b[39mfield_serializers)\n\u001b[0;32m    742\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m computed_fields\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    743\u001b[0m         ],\n\u001b[0;32m    744\u001b[0m         extras_schema\u001b[38;5;241m=\u001b[39mextras_schema,\n\u001b[0;32m    745\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    746\u001b[0m     )\n\u001b[0;32m    747\u001b[0m     inner_schema \u001b[38;5;241m=\u001b[39m apply_validators(fields_schema, decorators\u001b[38;5;241m.\u001b[39mroot_validators\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    748\u001b[0m     new_inner_schema \u001b[38;5;241m=\u001b[39m define_expected_missing_refs(inner_schema, recursively_defined_type_refs())\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1115\u001b[0m, in \u001b[0;36mGenerateSchema._generate_md_field_schema\u001b[1;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_md_field_schema\u001b[39m(\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1110\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1111\u001b[0m     field_info: FieldInfo,\n\u001b[0;32m   1112\u001b[0m     decorators: DecoratorInfos,\n\u001b[0;32m   1113\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mModelField:\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a ModelField to represent a model field.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1115\u001b[0m     common_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mmodel_field(\n\u001b[0;32m   1117\u001b[0m         common_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1118\u001b[0m         serialization_exclude\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserialization_exclude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1123\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1308\u001b[0m, in \u001b[0;36mGenerateSchema._common_field_schema\u001b[1;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_annotations(\n\u001b[0;32m   1305\u001b[0m             source_type, annotations \u001b[38;5;241m+\u001b[39m validators_from_decorators, transform_inner_schema\u001b[38;5;241m=\u001b[39mset_discriminator\n\u001b[0;32m   1306\u001b[0m         )\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1308\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidators_from_decorators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m this_field_validators \u001b[38;5;241m=\u001b[39m filter_field_decorator_info_by_field(decorators\u001b[38;5;241m.\u001b[39mvalidators\u001b[38;5;241m.\u001b[39mvalues(), name)\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2107\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations\u001b[1;34m(self, source_type, annotations, transform_inner_schema)\u001b[0m\n\u001b[0;32m   2102\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m     get_inner_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_inner_schema(\n\u001b[0;32m   2104\u001b[0m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[0;32m   2105\u001b[0m     )\n\u001b[1;32m-> 2107\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[0;32m   2109\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m CoreMetadataHandler(schema)\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:83\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[1;34m(self, source_type)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[1;32m---> 83\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2088\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2086\u001b[0m from_property \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_from_property(obj, source_type)\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_property \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2088\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2090\u001b[0m     schema \u001b[38;5;241m=\u001b[39m from_property\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:929\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[1;32m--> 929\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1029\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m   1027\u001b[0m origin \u001b[38;5;241m=\u001b[39m get_origin(obj)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_generic_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prepare_pydantic_annotations_for_known_type(obj, ())\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1058\u001b[0m, in \u001b[0;36mGenerateSchema._match_generic_type\u001b[1;34m(self, obj, origin)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_property\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39morigin_is_union(origin):\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_union_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m origin \u001b[38;5;129;01min\u001b[39;00m TUPLE_TYPES:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuple_schema(obj)\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1378\u001b[0m, in \u001b[0;36mGenerateSchema._union_schema\u001b[1;34m(self, union_type)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         nullable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         choices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1381\u001b[0m     s \u001b[38;5;241m=\u001b[39m choices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:657\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[1;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    655\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_inner(obj)\n\u001b[1;32m--> 657\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_get_pydantic_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     metadata_schema \u001b[38;5;241m=\u001b[39m resolve_original_schema(schema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefs\u001b[38;5;241m.\u001b[39mdefinitions)\n",
      "File \u001b[1;32mc:\\Users\\HamzaJadoon\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2447\u001b[0m, in \u001b[0;36m_extract_get_pydantic_json_schema\u001b[1;34m(tp, schema)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_custom_v2_modify_js_func:\n\u001b[0;32m   2446\u001b[0m         cls_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m   2448\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `__modify_schema__` method is not supported in Pydantic v2. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2449\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `__get_pydantic_json_schema__` instead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in class `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcls_name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2450\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom-json-schema\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2451\u001b[0m         )\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# handle GenericAlias' but ignore Annotated which \"lies\" about its origin (in this case it would be `int`)\u001b[39;00m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__origin__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_annotated(tp):\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/custom-json-schema"
     ]
    }
   ],
   "source": [
    "# import langchain\n",
    "# import numpy as np\n",
    "# from langchain_together import Together\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_together import Together\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac871e2-877f-47bb-bb3b-afa5e757cf30",
   "metadata": {},
   "source": [
    "# Pdf Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131a0ad1-3870-4892-8822-5a13ad9c0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# for multiple pdf files\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ea0b3c-05d2-48f5-92fb-120bb48a3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb1efd-6fa4-461d-b05e-5239a211a136",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2cd620e-b360-4409-99d5-e36ec91571b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# embeddings = OllamaEmbeddings()\n",
    "\n",
    "from langchain_together.embeddings import TogetherEmbeddings\n",
    "embeddings = TogetherEmbeddings(\n",
    "    model=\"togethercomputer/m2-bert-80M-8k-retrieval\",\n",
    "    together_api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\"                          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd43dc83-6ae7-48ce-b5a3-2b4f324d60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"dogs are good\"\n",
    "text2 = \"dogs are better\"\n",
    "text3 = \"israel is a country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cfa3419-4e7a-4fd2-917d-acd8942327b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_1 = embeddings.embed_query(text1)\n",
    "emb_2 = embeddings.embed_query(text2)\n",
    "emb_3 = embeddings.embed_query(text3)\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "cosine_similarity_1 = 1 - cosine(emb_1, emb_2)\n",
    "cosine_similarity_2 = 1 - cosine(emb_1, emb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d70279a-1da1-4376-b8d6-ad1683f50588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28266973618505165"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6af422-2e98-424a-b261-04acf9ffec76",
   "metadata": {},
   "source": [
    "# VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdd2c3-d656-4fe9-9cf8-4c02803fe7aa",
   "metadata": {},
   "source": [
    "FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8d75085-7e44-4e39-9537-6e7e9c019884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bac9e4e0-c0d9-4b8f-9461-8b49d4015b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d719a3-5933-4c77-84fc-a1c8daa7ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'docs/faiss/'\n",
    "vectordb.save_local(folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed57500d-b202-44e5-ba30-e33d4b48e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings()\n",
    "loaded_vectordb = FAISS.load_local(folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff57257-48a8-4ab0-a1fc-42a47f62a263",
   "metadata": {},
   "source": [
    "Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e07bb4b2-900e-4040-8aa8-c5ca34856f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# persist_directory = 'docs/chroma/file_n'\n",
    "# persist_directory = 'docs/chroma/vector-kaggle'\n",
    "persist_directory = 'docs/chroma/CSLectures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c91fff52-708c-4544-9f72-48779e7270f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=persist_directory\n",
    "# )\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92c19bf3-5122-400f-83f9-33221fd81990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing from local save\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e33c783-6cae-4032-ac2e-4e28df0c94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8924eec-af9a-44f8-bdce-6c3151ac80d0",
   "metadata": {},
   "source": [
    "# Similarity_Search + Max_Marginal_Relevance_Search\n",
    "``Similarity-search`` prioritizes finding the closest documents\n",
    "\n",
    "``MMR-search`` focuses on retrieving a set of documents that are both relevant and diverse, covering different aspects of the query\n",
    "\n",
    "**Similarity Search**: Use this when you simply want the most similar documents to the query, regardless of their redundancy. It's faster and easier to implement.\n",
    "\n",
    "**Max-Marginal Relevance Search**: Use this when you need a diverse set of documents that cover different aspects of the query. This is particularly helpful for tasks like document summarization or generating informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb3c406-564c-4470-a6a3-e6ba2b9f0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is Convolutional Neural Networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532de458-dc68-4e47-b531-449b581c082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0aa75103-c6a8-4072-b0ab-151f97c4ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying which file to retrieve info from\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=2,\n",
    "    filter={\"source\":\"file_1.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a144e15-e7da-4219-acbe-1c63d6d6be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0]\n",
    "# docs[1]\n",
    "# docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d335fd89-afa1-4ce8-a115-6796107a0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c36a5e4-1a2a-4a76-bd31-851929b4c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0]\n",
    "# docs[1]\n",
    "# docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd3ff06-0cf2-446c-8f96-d17801cd3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].metadata\n",
    "# docs[1].metadata\n",
    "# docs[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a33c87c-6e2e-464f-9215-5254cdcd727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import Together\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = Together(\n",
    "#     model=\"META-LLAMA/LLAMA-2-7B-CHAT-HF\",\n",
    "#     together_api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\"\n",
    "# )\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\",\n",
    "    model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba744b2d-0c7c-40f5-9e43-91f59bbdfeeb",
   "metadata": {},
   "source": [
    "# Retriever Types\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030d8d5-66a7-4a89-8d23-dd41f25de6e9",
   "metadata": {},
   "source": [
    "### Self-Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10d280f7-dd50-4aa8-b15f-2b751e6d2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7da1db8-53ca-43f7-8600-fbe52007f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"lectures on machine learning based on three pdf files: file_1.pdf, file_2.pdf, file_3.pdf\",  \n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page number within the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1fe956fd-878c-4345-aca4-9dba5c2fedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable stores a brief description of the content of the documents in the vectordb. \n",
    "# In this case, it's set to \"Lecture notes\", indicating that the documents are lecture notes.\n",
    "document_content_description = \"Lectures on machine learning\"\n",
    "\n",
    "# llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "    model,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20f39a8e-372d-445b-8bba-bc4f2bde1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = self_query_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "327a5e79-6256-41e5-abeb-457f80b7fe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b095beb6-c288-475f-87e7-cfd7026d50a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 16, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 1, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 9, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 5, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f3d1fb-715b-4fb4-88d6-6eae4fe6ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Clustering is a method of unsupervised learning that involves grouping a set of objects in such a \\nway that objects in the same group (cluster) are more similar to each other than to those in other \\ngroups.  \\n• k-Means Clustering : Partitions the data into k clusters by minimizing the variance \\nwithin each cluster.  \\n• Hierarchical Clustering : Builds a hierarchy of clusters either through a bottom -up \\n(agglomerative) or top -down (divisive) approach.  \\n• DBSCAN (Density -Based Spatial Clustering of Applications with Noise) : Groups \\ntogether points that are close to each other based on a distance measurement, and marks \\npoints that are in low -density regions as outliers.  \\nDimensionality Reduction  \\nDimensionality reduction is the process of reducing the number of random variables under \\nconsideration by obtaining a set of principal variables.  \\n• Principal Component Analysis (PCA) : Projects the data into a lower -dimensional space \\nby maximizing the variance along the principal components.  \\n• t-Distributed Stochastic Neighbor Embedding (t -SNE) : Primarily used for visualizing \\nhigh-dimensional data by reducing it to two or three dimensions.  \\n• Linear Discriminant Analysis (LDA) : Finds the linear combinations of features that \\nbest separate two or more classes of objects or events.  \\nAnomaly Detection  \\nAnomaly detection aims to identify rare items, events, or observations that raise suspicions by \\ndiffering significantly from the majority of the data.  \\n• Statistical Methods : Assume a statistical distribution for the data and identify points that \\ndeviate significantly from this distribution.  \\n• Machine Learning Methods : Include clustering -based methods (e.g., DBSCAN) and \\nmodel -based approaches (e.g., autoencoders).  \\nAssociation Rules  \\nAssociation rule learning is a rule -based machine learning method for discovering interesting \\nrelations between variables in large databases.  \\n• Apriori Algorithm : Identifies frequent itemsets and then derives association rules from \\nthese itemsets.  \\n• Eclat Algorithm : Uses a depth -first search strategy to find frequent itemsets and is often \\nfaster than Apriori for large datasets.  \\n ', metadata={'page': 2, 'source': 'file_1.pdf'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9100f-63c0-499b-bd11-58d0c5c61fc7",
   "metadata": {},
   "source": [
    "### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b484d989-ffd4-4b63-82db-e13c63beb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9464fe85-50fc-48b9-9201-17daf0ef602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is supervised learning?\"\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a77435-c43a-4437-8e53-e4dc3ba29501",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16c25b2f-b491-4a13-94de-fc73443b5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d6b7e2d-ab03-43b9-a375-43811cd4cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "NO_OUTPUT. There is no relevant part of the context that is related to the question \"what is supervised learning?\". The context appears to be about administrative announcements, grading assignments, and linear regression, but does not mention supervised learning.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Here are the extracted relevant parts:\n",
      "\n",
      "So in supervised learning, this is what we 're going to do. We're given a training set, and we're going to feed our training set, compri sing our M training example, so 47 training examples, into a learning algorithm. Okay, and our algorithm then has output function that is by tradition, and for hist orical reasons, is usually de noted lower case alphabet H, and is called a hypothesis.\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c51c624-a562-48f1-8b2d-ec762d25a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 3, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture02.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in compressed_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c94c2-8391-4ba2-8153-11c893fc8b3e",
   "metadata": {},
   "source": [
    "# Legacy Chains ~ retrievers\n",
    "\n",
    "### - RetrievalQA\n",
    "### - ConversationalRetrievalChain\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/chains/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed16e53-a98f-4484-b822-4bc766488aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:23:37 - Created default config file at D:\\Work\\NLP\\Langchain\\.chainlit\\config.toml\n",
      "2024-07-01 17:23:37 - Created default translation directory at D:\\Work\\NLP\\Langchain\\.chainlit\\translations\n",
      "2024-07-01 17:23:37 - Created default translation file at D:\\Work\\NLP\\Langchain\\.chainlit\\translations\\en-US.json\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72671b0d-f72e-4deb-8dc1-c899aee37f94",
   "metadata": {},
   "source": [
    "##### ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fb781840-c4be-402e-9917-62e652170425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    model,\n",
    "    memory=memory,\n",
    "    retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    "    # retriever=self_query_retriever,\n",
    "    # retriever=compression_retriever,  \n",
    "\n",
    "    # return_source_documents=True,\n",
    "    # chain_type=\"map_reduce\"\n",
    "    # chain_type=\"refine\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "aac74530-12dc-4ce1-bebd-2556371c69fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who is the lecturer?',\n",
       " 'chat_history': [HumanMessage(content='who is the lecturer?'),\n",
       "  AIMessage(content='The lecturer in this context is Andrew Ng, a well-known artificial intelligence researcher and entrepreneur. At the time of this recording, he was an assistant professor at Stanford University and was teaching a class on machine learning.')],\n",
       " 'answer': 'The lecturer in this context is Andrew Ng, a well-known artificial intelligence researcher and entrepreneur. At the time of this recording, he was an assistant professor at Stanford University and was teaching a class on machine learning.'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"question\": \"who is the lecturer?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0614671f-84f3-40b6-a23f-efe674532c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa({\"question\": \"what does he teach\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca1f04e-1ac1-4a26-904b-13a8f4012811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa({\"question\": \"what is supervised learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e14342-59b5-4b5c-9a1a-e65b389401a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in memory:\n",
    "#     for j in i:\n",
    "#         print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924e268-44b4-4e6f-a92f-a36f51daa472",
   "metadata": {},
   "source": [
    "##### RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1f9212cb-2bb0-4540-8887-5f1cf703d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "90714ceb-8044-4afa-9173-40caaf3a4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    \n",
    "    model,\n",
    "    retriever=vectordb.as_retriever(search_type = \"mmr\"),\n",
    "    # retriever=self_query_retriever,\n",
    "    # retriever=compression_retriever,  \n",
    "\n",
    "    return_source_documents=True,\n",
    "    # chain_type=\"map_reduce\"\n",
    "    # chain_type=\"refine\"\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9898355c-610b-4d1a-9acc-95be69afa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain({\"query\": \"who are the TAs\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
