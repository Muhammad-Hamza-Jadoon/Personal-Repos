{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afdebb3-094a-453e-a6c5-6b4cbd2bfba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_together import Together\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0df8cc-1333-4c77-92b1-10285e6993bb",
   "metadata": {},
   "source": [
    "<!-- - ## Go to https://api.together.ai\n",
    "- ## Make an account and sign in\n",
    "- ## Go to settings/api_keys. Generate one and use it as together_api_key -->\n",
    "\n",
    "- **Get a Together API Key:**\n",
    "    * Visit the Together.ai API website: https://api.together.ai\n",
    "    * Create an account and sign in.\n",
    "    * Navigate to your settings and then the API keys section.\n",
    "    * Generate a new API key and copy it for later use. \n",
    "\n",
    "**Note:** Replace together_api_key with your actual key in the code snippet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1280c96a-0026-4603-91f4-7a9efc92b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Together(\n",
    "    model=\"META-LLAMA/LLAMA-2-7B-CHAT-HF\",\n",
    "    together_api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\",\n",
    "    model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42e8b6-3f24-40f6-8acd-1c32cc6acfe5",
   "metadata": {},
   "source": [
    "## **Now suppose you want to chat with the model by providing it with some additional context in the form of text**\n",
    "\n",
    "#### Vector store takes in two inputs: Data (simple text in our case), and pre-trained embedding model (ollamaembeddings in our case). ```It then embeds the provided text```\n",
    "#### First up create a vector store and store your text in it. To use this vector store, you must retrieve it and store in a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96794a90-533d-43d1-91f8-372aa40b72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza Jadoon\\AppData\\Roaming\\Python\\Python310\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# Creating vector store\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"alex is looking for a job\", \"alex likes to visit parks becuase they are green\"],\n",
    "    embedding = OllamaEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874a3741-d994-47c0-9078-0ae00c1be841",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29633c3-4752-4b49-93ab-97f7e8372427",
   "metadata": {},
   "source": [
    "**You will have to understand how the following work:**\n",
    "\n",
    " * RunnableParallel\n",
    " * RunnablePassthrough\n",
    "\n",
    "**It has been explained to you in the following image:**\n",
    "\n",
    "<img src=\"img_.jpg\" alt=\"Alt text for image\" style=\"width: 800px; height: 600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335666ab-70c1-4a56-9fdd-da5ad94490bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the context, Alex is looking for a job.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnableParallel runs multiple tasks at the same time\n",
    "# RunnablePassthrough simply passes on the retrieved text/doc into \"context\"\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "# Notice how chain is created where setup_and_retrieval is connected to prompts chain\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "chain.invoke(\"what is alex doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13810053-21b3-4610-8b30-59256c2fa99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the context, Alex likes to visit parks because they are green.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"why does alex like to visit parks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16157e5-0908-4a4b-8549-a2579f18d11c",
   "metadata": {},
   "source": [
    "# Now Lets up our game and implement a simple RAG model\n",
    "\n",
    "<span style=\"font-size: 18px;\">RAG (Retrieval-Augmented Generation) is a technique where a system first looks up relevant information from provided sources (websites/pdf etc) and then uses that information to generate reponse</span>\n",
    "#### Following creates two vector stores: \n",
    " * website\n",
    " * pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c32df3-a689-4f32-a5d1-4c1f01e199ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local pdf file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"QA-with-RAG/basic.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c05b9b-0e46-495c-ba89-94acd87a40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "pdf_doc = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9044a8a-8284-4393-a6fe-ec598448d6f5",
   "metadata": {},
   "source": [
    "### Now you can use many different types of vector stores like chroma etc. I used FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fbc038-b71b-44e0-a1fd-c80d1e16e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context: \n",
    "<context> \n",
    "{context} \n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862a570-efc5-4737-9ea0-03c42becb026",
   "metadata": {},
   "source": [
    "<img src=\"work.jpg\" alt=\"Alt text for image\" style=\"width: 800px; height: 600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9df2feb-7323-471b-8eed-521753633cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_vector = FAISS.from_documents(pdf_doc, embeddings)\n",
    "pdf_retriever = pdf_vector.as_retriever()\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "pdf_document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "pdf_retrieval_chain = create_retrieval_chain(pdf_retriever, pdf_document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1931f23c-0c42-47ce-bd5d-cf6f8ac0baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pdf_retrieval_chain.invoke({\"input\": \"Who is alex?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd86062c-935e-4b7e-a5aa-3932f15064ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is alex?',\n",
       " 'context': [Document(page_content=\"Once upon a time in the bustling city of Brooksville, Alex, a dedicated software engineer, found \\nhimself facing unexpected adversity. Alex had poured his heart and soul into his job at Tech \\nInnovations, a startup renowned for its cutting -edge technology solutions. He was the go -to guy \\nfor troubleshooting, innovation, and camaraderie in the office.  \\nHowever, one gloomy Monday morning, Alex was called into the CEO's office. His heart raced \\nwith anticipation, but his hopes were shattered when he was informed that due to restructuring, \\nhis position was being eliminated. Shock washed over him like an icy wave crashing onto the \\nshore. His mind buzzed with disbelief and fear as he absorbed the reality of his sudden \\nunemployment.  \\nFeeling lost and uncertain about the future, Alex wandered the streets of Brooksville, his mind \\nclouded with worry. Days turned into weeks, and the weight of unemployment hung heavy on \\nhis shoulders. The once -familiar rhythm of office life was replaced by a disheartening silence.  \\nBut amidst the despair, a glimmer of hope emerged. Alex rediscovered his passion for coding \\nand began to spend his days honing his skills, exploring new technologies, and nurturing his \\nentrepreneurial spirit. He attended networking events, collaborated wit h fellow tech enthusiasts, \\nand delved into personal projects that had long been on the back burner.  \\nAs weeks turned into months, Alex's hard work and determination bore fruit. He landed \\nfreelance gigs, developed his own apps, and even started teaching coding classes at a local \\ncommunity center. Through resilience and perseverance, Alex transformed his se tback into an \\nopportunity for growth and self -discovery.  \\nWith each new challenge he faced, Alex grew stronger and more confident. He realized that \\nlosing his job was not the end of his story but merely the beginning of a new chapter filled with \\nendless possibilities. And as he looked towards the horizon with ren ewed optimism, he knew \\nthat whatever the future held, he was ready to embrace it with open arms.\", metadata={'source': 'QA-with-RAG/basic.pdf', 'page': 0})],\n",
       " 'answer': '</answer>\\n\\nAlex is a software engineer.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5ee67-fb57-4bb2-bf9c-c91428414df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baded646-945b-4d47-b28d-03080e017b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5402e-6121-4f20-b03f-f77fab98099c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ace2d-0adf-40fd-b198-4889ab26f1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc096d4-eb60-43d1-896e-72077771d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60826fd2-ba89-4696-b432-c77222a64846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
