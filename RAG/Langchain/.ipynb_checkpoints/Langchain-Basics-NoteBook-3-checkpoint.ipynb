{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13bab812-9a26-48f8-9d03-27e32d02d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import numpy as np\n",
    "from langchain_together import Together\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac871e2-877f-47bb-bb3b-afa5e757cf30",
   "metadata": {},
   "source": [
    "# Pdf Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131a0ad1-3870-4892-8822-5a13ad9c0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# for multiple pdf files\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ea0b3c-05d2-48f5-92fb-120bb48a3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb1efd-6fa4-461d-b05e-5239a211a136",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2cd620e-b360-4409-99d5-e36ec91571b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# embeddings = OllamaEmbeddings()\n",
    "\n",
    "from langchain_together.embeddings import TogetherEmbeddings\n",
    "embeddings = TogetherEmbeddings(\n",
    "    model=\"togethercomputer/m2-bert-80M-8k-retrieval\",\n",
    "    together_api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\"                          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd43dc83-6ae7-48ce-b5a3-2b4f324d60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"dogs are good\"\n",
    "text2 = \"dogs are better\"\n",
    "text3 = \"israel is a country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cfa3419-4e7a-4fd2-917d-acd8942327b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_1 = embeddings.embed_query(text1)\n",
    "emb_2 = embeddings.embed_query(text2)\n",
    "emb_3 = embeddings.embed_query(text3)\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "cosine_similarity_1 = 1 - cosine(emb_1, emb_2)\n",
    "cosine_similarity_2 = 1 - cosine(emb_1, emb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d70279a-1da1-4376-b8d6-ad1683f50588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28266973618505165"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6af422-2e98-424a-b261-04acf9ffec76",
   "metadata": {},
   "source": [
    "# VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdd2c3-d656-4fe9-9cf8-4c02803fe7aa",
   "metadata": {},
   "source": [
    "FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8d75085-7e44-4e39-9537-6e7e9c019884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bac9e4e0-c0d9-4b8f-9461-8b49d4015b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d719a3-5933-4c77-84fc-a1c8daa7ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'docs/faiss/'\n",
    "vectordb.save_local(folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed57500d-b202-44e5-ba30-e33d4b48e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings()\n",
    "loaded_vectordb = FAISS.load_local(folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff57257-48a8-4ab0-a1fc-42a47f62a263",
   "metadata": {},
   "source": [
    "Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e07bb4b2-900e-4040-8aa8-c5ca34856f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# persist_directory = 'docs/chroma/file_n'\n",
    "# persist_directory = 'docs/chroma/vector-kaggle'\n",
    "persist_directory = 'docs/chroma/CSLectures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c91fff52-708c-4544-9f72-48779e7270f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=persist_directory\n",
    "# )\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92c19bf3-5122-400f-83f9-33221fd81990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing from local save\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e33c783-6cae-4032-ac2e-4e28df0c94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8924eec-af9a-44f8-bdce-6c3151ac80d0",
   "metadata": {},
   "source": [
    "# Similarity_Search + Max_Marginal_Relevance_Search\n",
    "``Similarity-search`` prioritizes finding the closest documents\n",
    "\n",
    "``MMR-search`` focuses on retrieving a set of documents that are both relevant and diverse, covering different aspects of the query\n",
    "\n",
    "**Similarity Search**: Use this when you simply want the most similar documents to the query, regardless of their redundancy. It's faster and easier to implement.\n",
    "\n",
    "**Max-Marginal Relevance Search**: Use this when you need a diverse set of documents that cover different aspects of the query. This is particularly helpful for tasks like document summarization or generating informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb3c406-564c-4470-a6a3-e6ba2b9f0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is Convolutional Neural Networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532de458-dc68-4e47-b531-449b581c082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0aa75103-c6a8-4072-b0ab-151f97c4ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying which file to retrieve info from\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=2,\n",
    "    filter={\"source\":\"file_1.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a144e15-e7da-4219-acbe-1c63d6d6be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0]\n",
    "# docs[1]\n",
    "# docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d335fd89-afa1-4ce8-a115-6796107a0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c36a5e4-1a2a-4a76-bd31-851929b4c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0]\n",
    "# docs[1]\n",
    "# docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd3ff06-0cf2-446c-8f96-d17801cd3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].metadata\n",
    "# docs[1].metadata\n",
    "# docs[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a33c87c-6e2e-464f-9215-5254cdcd727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import Together\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = Together(\n",
    "#     model=\"META-LLAMA/LLAMA-2-7B-CHAT-HF\",\n",
    "#     together_api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\"\n",
    "# )\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=\"24cdbdf50106e08f6ba3328ac07f97a73eb440ae36da6cdd72f9b091ccca850a\",\n",
    "    model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba744b2d-0c7c-40f5-9e43-91f59bbdfeeb",
   "metadata": {},
   "source": [
    "# Retriever Types\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030d8d5-66a7-4a89-8d23-dd41f25de6e9",
   "metadata": {},
   "source": [
    "### Self-Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10d280f7-dd50-4aa8-b15f-2b751e6d2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7da1db8-53ca-43f7-8600-fbe52007f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"lectures on machine learning based on three pdf files: file_1.pdf, file_2.pdf, file_3.pdf\",  \n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page number within the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1fe956fd-878c-4345-aca4-9dba5c2fedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable stores a brief description of the content of the documents in the vectordb. \n",
    "# In this case, it's set to \"Lecture notes\", indicating that the documents are lecture notes.\n",
    "document_content_description = \"Lectures on machine learning\"\n",
    "\n",
    "# llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "    model,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20f39a8e-372d-445b-8bba-bc4f2bde1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = self_query_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "327a5e79-6256-41e5-abeb-457f80b7fe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b095beb6-c288-475f-87e7-cfd7026d50a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 16, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 1, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 9, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 5, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f3d1fb-715b-4fb4-88d6-6eae4fe6ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Clustering is a method of unsupervised learning that involves grouping a set of objects in such a \\nway that objects in the same group (cluster) are more similar to each other than to those in other \\ngroups.  \\n• k-Means Clustering : Partitions the data into k clusters by minimizing the variance \\nwithin each cluster.  \\n• Hierarchical Clustering : Builds a hierarchy of clusters either through a bottom -up \\n(agglomerative) or top -down (divisive) approach.  \\n• DBSCAN (Density -Based Spatial Clustering of Applications with Noise) : Groups \\ntogether points that are close to each other based on a distance measurement, and marks \\npoints that are in low -density regions as outliers.  \\nDimensionality Reduction  \\nDimensionality reduction is the process of reducing the number of random variables under \\nconsideration by obtaining a set of principal variables.  \\n• Principal Component Analysis (PCA) : Projects the data into a lower -dimensional space \\nby maximizing the variance along the principal components.  \\n• t-Distributed Stochastic Neighbor Embedding (t -SNE) : Primarily used for visualizing \\nhigh-dimensional data by reducing it to two or three dimensions.  \\n• Linear Discriminant Analysis (LDA) : Finds the linear combinations of features that \\nbest separate two or more classes of objects or events.  \\nAnomaly Detection  \\nAnomaly detection aims to identify rare items, events, or observations that raise suspicions by \\ndiffering significantly from the majority of the data.  \\n• Statistical Methods : Assume a statistical distribution for the data and identify points that \\ndeviate significantly from this distribution.  \\n• Machine Learning Methods : Include clustering -based methods (e.g., DBSCAN) and \\nmodel -based approaches (e.g., autoencoders).  \\nAssociation Rules  \\nAssociation rule learning is a rule -based machine learning method for discovering interesting \\nrelations between variables in large databases.  \\n• Apriori Algorithm : Identifies frequent itemsets and then derives association rules from \\nthese itemsets.  \\n• Eclat Algorithm : Uses a depth -first search strategy to find frequent itemsets and is often \\nfaster than Apriori for large datasets.  \\n ', metadata={'page': 2, 'source': 'file_1.pdf'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9100f-63c0-499b-bd11-58d0c5c61fc7",
   "metadata": {},
   "source": [
    "### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b484d989-ffd4-4b63-82db-e13c63beb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9464fe85-50fc-48b9-9201-17daf0ef602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is supervised learning?\"\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a77435-c43a-4437-8e53-e4dc3ba29501",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16c25b2f-b491-4a13-94de-fc73443b5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d6b7e2d-ab03-43b9-a375-43811cd4cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\envs\\test\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "NO_OUTPUT. There is no relevant part of the context that is related to the question \"what is supervised learning?\". The context appears to be about administrative announcements, grading assignments, and linear regression, but does not mention supervised learning.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Here are the extracted relevant parts:\n",
      "\n",
      "So in supervised learning, this is what we 're going to do. We're given a training set, and we're going to feed our training set, compri sing our M training example, so 47 training examples, into a learning algorithm. Okay, and our algorithm then has output function that is by tradition, and for hist orical reasons, is usually de noted lower case alphabet H, and is called a hypothesis.\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c51c624-a562-48f1-8b2d-ec762d25a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 3, 'source': '/kaggle/input/cslectures/MachineLearning-Lecture02.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in compressed_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c94c2-8391-4ba2-8153-11c893fc8b3e",
   "metadata": {},
   "source": [
    "# Legacy Chains ~ retrievers\n",
    "\n",
    "### - RetrievalQA\n",
    "### - ConversationalRetrievalChain\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/chains/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed16e53-a98f-4484-b822-4bc766488aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:23:37 - Created default config file at D:\\Work\\NLP\\Langchain\\.chainlit\\config.toml\n",
      "2024-07-01 17:23:37 - Created default translation directory at D:\\Work\\NLP\\Langchain\\.chainlit\\translations\n",
      "2024-07-01 17:23:37 - Created default translation file at D:\\Work\\NLP\\Langchain\\.chainlit\\translations\\en-US.json\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72671b0d-f72e-4deb-8dc1-c899aee37f94",
   "metadata": {},
   "source": [
    "##### ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fb781840-c4be-402e-9917-62e652170425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    model,\n",
    "    memory=memory,\n",
    "    retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    "    # retriever=self_query_retriever,\n",
    "    # retriever=compression_retriever,  \n",
    "\n",
    "    # return_source_documents=True,\n",
    "    # chain_type=\"map_reduce\"\n",
    "    # chain_type=\"refine\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "aac74530-12dc-4ce1-bebd-2556371c69fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who is the lecturer?',\n",
       " 'chat_history': [HumanMessage(content='who is the lecturer?'),\n",
       "  AIMessage(content='The lecturer in this context is Andrew Ng, a well-known artificial intelligence researcher and entrepreneur. At the time of this recording, he was an assistant professor at Stanford University and was teaching a class on machine learning.')],\n",
       " 'answer': 'The lecturer in this context is Andrew Ng, a well-known artificial intelligence researcher and entrepreneur. At the time of this recording, he was an assistant professor at Stanford University and was teaching a class on machine learning.'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"question\": \"who is the lecturer?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0614671f-84f3-40b6-a23f-efe674532c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa({\"question\": \"what does he teach\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca1f04e-1ac1-4a26-904b-13a8f4012811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa({\"question\": \"what is supervised learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e14342-59b5-4b5c-9a1a-e65b389401a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in memory:\n",
    "#     for j in i:\n",
    "#         print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924e268-44b4-4e6f-a92f-a36f51daa472",
   "metadata": {},
   "source": [
    "##### RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1f9212cb-2bb0-4540-8887-5f1cf703d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "90714ceb-8044-4afa-9173-40caaf3a4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    \n",
    "    model,\n",
    "    retriever=vectordb.as_retriever(search_type = \"mmr\"),\n",
    "    # retriever=self_query_retriever,\n",
    "    # retriever=compression_retriever,  \n",
    "\n",
    "    return_source_documents=True,\n",
    "    # chain_type=\"map_reduce\"\n",
    "    # chain_type=\"refine\"\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9898355c-610b-4d1a-9acc-95be69afa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain({\"query\": \"who are the TAs\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
